{
  "id": "openai:tool_call:parallel",
  "description": "Chat completion with parallel tool calls response",
  "request": {
    "method": "POST",
    "path": "/chat/completions"
  },
  "response": {
    "status": 200,
    "headers": {
      "content-type": "application/json",
      "x-ratelimit-remaining-tokens": "199988",
      "x-ratelimit-reset-tokens": "3ms",
      "x-ratelimit-reset-requests": "40.32s",
      "x-ratelimit-remaining-requests": "9995",
      "x-request-id": "req_9b85fd4e9acb45ea9d20a274b25b096a",
      "x-ratelimit-limit-tokens": "200000",
      "x-envoy-upstream-service-time": "3851",
      "x-openai-proxy-wasm": "v0.1",
      "x-content-type-options": "nosniff",
      "x-ratelimit-limit-requests": "10000"
    },
    "body": {
      "choices": [
        {
          "finish_reason": "tool_calls",
          "index": 0,
          "logprobs": null,
          "message": {
            "annotations": [],
            "content": null,
            "refusal": null,
            "role": "assistant",
            "tool_calls": [
              {
                "function": {
                  "arguments": "{\"location\": \"Tokyo, Japan\"}",
                  "name": "get_weather"
                },
                "id": "call_TjX4G9H466ItkuBseHA6BGTq",
                "type": "function"
              },
              {
                "function": {
                  "arguments": "{\"location\": \"London, UK\"}",
                  "name": "get_weather"
                },
                "id": "call_6rVnHCS5SPffFe09GJWTH9z9",
                "type": "function"
              }
            ]
          }
        }
      ],
      "created": 1766147498,
      "id": "chatcmpl-CoTvu8b4sDLWnCeZ8QQnWOEnm5J41",
      "model": "gpt-4o-mini-2024-07-18",
      "object": "chat.completion",
      "service_tier": "default",
      "system_fingerprint": "fp_29330a9688",
      "usage": {
        "completion_tokens": 48,
        "completion_tokens_details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 0,
          "rejected_prediction_tokens": 0
        },
        "prompt_tokens": 83,
        "prompt_tokens_details": {
          "audio_tokens": 0,
          "cached_tokens": 0
        },
        "total_tokens": 131
      }
    }
  }
}